{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAmbuske02/Pi-in-the-Sky/blob/main/Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning for Remote Reconnaisance Project\n",
        "\n",
        "In this research project, I combine the latest deeplearning models for computer vision together with a camera-augmented Raspberry Pi, to enable a modified RC plane to identify people, objects, and targets from the sky.\n",
        "\n",
        "The fundamental research problem addressed in this study is: investigating the tradeoff between a computer vision model's target identification accuracy and its ability to run on hardware with substantial power and weight limitations. I investigate whether the latest pretrained deeplearning models from GoogleAI were appropriate for target identication."
      ],
      "metadata": {
        "id": "loeCwxcbHuMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are many deep learning models available for general object identification. However, as we ultimately want this model to run on airborne computer hardware, it is crucial that the algorithm run without the enormous computational requirements typical of many models.\n",
        "\n",
        "I ultimately found that Google's [*MobileNets*](https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html) family of computer vision models for tensorflow offered a reasonable balace between algorithm performance and hardware requirements.  \n",
        "\n",
        "More specifically I used Google's MobileNetV2 deep learning pretrained model. MobileNetV2 was designed to have a much smaller parameter count than typical computer vision models. A smaller model is more ideal to ultimately run with lower processing power, which will be deal for running on a UAV.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L5bo7UCs1TbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Google's tensorflow open source software library for deeplearning and applied it to the target identification problem."
      ],
      "metadata": {
        "id": "fSnOw21GFHbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we install the tensorflow models into the colab environment  \n",
        "!git clone https://github.com/tensorflow/models\n",
        "\n"
      ],
      "metadata": {
        "id": "Hhgp6_Td0dmZ",
        "outputId": "4e9da56c-f7c3-4a84-b6a0-627c12fe3aae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 77698, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 77698 (delta 36), reused 37 (delta 18), pack-reused 77621\u001b[K\n",
            "Receiving objects: 100% (77698/77698), 593.34 MiB | 40.33 MiB/s, done.\n",
            "Resolving deltas: 100% (55195/55195), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many deep learning models available for general object identification. However, as we ultimately want this model to run on airborne computer hardware, it is crucial that the algorithm run without the enormous computational requirements typical of many models.\n",
        "\n",
        "In this project I used Google's *MobileNets* family of computer vision models for tensorflow offered a reasonable balance between algorithm performance and hardware requirements.  \n",
        "\n",
        "More specifically I used Google's MobileNetV2 deep learning pretrained model. MobileNetV2 has a much smaller parameter count. A smaller model is more ideal to ultimately run with lower processing power, which will be deal for running on a UAV."
      ],
      "metadata": {
        "id": "8BYwQhcXFMz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we download the mobilenet 2 model\n",
        "from __future__ import print_function\n",
        "from IPython import display \n",
        "base_name = checkpoint_name = 'mobilenet_v2_1.0_224' #@param\n",
        "url = 'https://storage.googleapis.com/mobilenet_v2/checkpoints/' + checkpoint_name + '.tgz'\n",
        "print('Downloading from ', url)\n",
        "!wget {url}\n",
        "print('Unpacking')\n",
        "!tar -xvf {checkpoint_name}.tgz\n",
        "checkpoint = checkpoint_name + '.ckpt'\n",
        "\n",
        "display.clear_output()\n",
        "print('Successfully downloaded checkpoint from ', url,\n",
        "      '. It is available as', checkpoint)\n"
      ],
      "metadata": {
        "id": "vcy9qBznE-jg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a3ac104-83a7-4280-d554-181fe2711b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded checkpoint from  https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz . It is available as mobilenet_v2_1.0_224.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG -O panda.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fON2yg7mKdVc",
        "outputId": "1dd69447-0c35-4f3e-b607-827df98883a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-30 20:52:03--  https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116068 (113K) [image/jpeg]\n",
            "Saving to: ‘panda.jpg’\n",
            "\n",
            "\rpanda.jpg             0%[                    ]       0  --.-KB/s               \rpanda.jpg           100%[===================>] 113.35K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2022-09-30 20:52:03 (23.2 MB/s) - ‘panda.jpg’ saved [116068/116068]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we install tf_slim, a lightweight library for  \n",
        "# evaluating models in TensorFlow\n",
        "import sys\n",
        "sys.path.append('/content/models/research/slim')\n",
        "!pip install tf_slim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSFRv6j5ISFe",
        "outputId": "0ae77e1d-bdea-49e0-9ed0-3381e36359ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the trained model into tensorflow\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tf_slim as slim\n",
        "from nets.mobilenet import mobilenet_v2\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# For simplicity we just decode jpeg inside tensorflow.\n",
        "# But one can provide any input obviously.\n",
        "file_input = tf.placeholder(tf.string, ())\n",
        "\n",
        "image = tf.image.decode_jpeg(tf.read_file(file_input))\n",
        "\n",
        "images = tf.expand_dims(image, 0)\n",
        "images = tf.cast(images, tf.float32) / 128.  - 1\n",
        "images.set_shape((None, None, None, 3))\n",
        "images = tf.image.resize_images(images, (224, 224))\n",
        "\n",
        "# Note: arg_scope is optional for inference.\n",
        "with slim.arg_scope(mobilenet_v2.training_scope(is_training=False)):\n",
        "  logits, endpoints = mobilenet_v2.mobilenet(images)\n",
        "  \n",
        "# Restore using exponential moving average since it produces (1.5-2%) higher \n",
        "# accuracy\n",
        "ema = tf.train.ExponentialMovingAverage(0.999)\n",
        "vars = ema.variables_to_restore()\n",
        "\n",
        "saver = tf.train.Saver(vars)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM_fcvUHJjyV",
        "outputId": "d07ae83f-7be1-4a31-e25c-952f8bce89fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  outputs = layer.apply(inputs, training=is_training)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Images\n",
        "Here we demonstrate processing of images to generate text labels for the target candidates."
      ],
      "metadata": {
        "id": "rQzQs2gfGpP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The wget command downloads images from the internet.\n",
        "!wget 'https://www.defensenews.com/resizer/U2oS79JL6Z7cX9bXU9zUMBI9bJk=/1024x0/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/OIFRAG2XKFDPPKI5KVUURA5474.jpg' -O sideTank.jpg\n",
        "!wget https://thumbs.dreamstime.com/z/us-marines-marching-bucharest-romania-december-aerial-photo-united-states-soldiers-romania-s-national-day-military-63207644.jpg -O soldiers.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfbS53zVGnbI",
        "outputId": "e991037a-2bcc-4076-8674-9aac3284e76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-03 17:11:42--  https://www.defensenews.com/resizer/U2oS79JL6Z7cX9bXU9zUMBI9bJk=/1024x0/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/OIFRAG2XKFDPPKI5KVUURA5474.jpg\n",
            "Resolving www.defensenews.com (www.defensenews.com)... 23.215.176.48, 23.215.176.49, 2600:1409:5000::1723:6219, ...\n",
            "Connecting to www.defensenews.com (www.defensenews.com)|23.215.176.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77080 (75K) [image/jpeg]\n",
            "Saving to: ‘sideTank.jpg’\n",
            "\n",
            "\rsideTank.jpg          0%[                    ]       0  --.-KB/s               \rsideTank.jpg        100%[===================>]  75.27K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2022-10-03 17:11:42 (8.84 MB/s) - ‘sideTank.jpg’ saved [77080/77080]\n",
            "\n",
            "--2022-10-03 17:11:43--  https://thumbs.dreamstime.com/z/us-marines-marching-bucharest-romania-december-aerial-photo-united-states-soldiers-romania-s-national-day-military-63207644.jpg\n",
            "Resolving thumbs.dreamstime.com (thumbs.dreamstime.com)... 192.229.163.122\n",
            "Connecting to thumbs.dreamstime.com (thumbs.dreamstime.com)|192.229.163.122|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 326076 (318K) [image/jpeg]\n",
            "Saving to: ‘soldiers.jpg’\n",
            "\n",
            "soldiers.jpg        100%[===================>] 318.43K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-10-03 17:11:43 (10.1 MB/s) - ‘soldiers.jpg’ saved [326076/326076]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://www.defensenews.com/resizer/U2oS79JL6Z7cX9bXU9zUMBI9bJk=/1024x0/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/OIFRAG2XKFDPPKI5KVUURA5474.jpg' width=300>"
      ],
      "metadata": {
        "id": "iXrvy3stH_l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "import pylab\n",
        "from datasets import imagenet\n",
        "import PIL\n",
        "#display.display(display.Image('sideTank.jpg'))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  saver.restore(sess,  checkpoint)\n",
        "  x = endpoints['Predictions'].eval(feed_dict={file_input: 'sideTank.jpg'})\n",
        "label_map = imagenet.create_readable_names_for_imagenet_labels()  \n",
        "print(\"Top 1 prediction: \", x.argmax(),label_map[x.argmax()], x.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TOKqcZxH18X",
        "outputId": "b252ccf6-016d-416f-a221-416015444718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 prediction:  848 tank, army tank, armored combat vehicle, armoured combat vehicle 0.82173944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This demonstrates that the stripped down minimal mobelnetV2 model is still capable of identifying tanks."
      ],
      "metadata": {
        "id": "QroCg9I0L6la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add image where it fails"
      ],
      "metadata": {
        "id": "3dvkmZTYMFdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://thumbs.dreamstime.com/z/us-marines-marching-bucharest-romania-december-aerial-photo-united-states-soldiers-romania-s-national-day-military-63207644.jpg width=300>"
      ],
      "metadata": {
        "id": "9POWA-RC1U-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "import pylab\n",
        "from datasets import imagenet\n",
        "import PIL\n",
        "#display.display(display.Image('sideTank.jpg'))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  saver.restore(sess,  checkpoint)\n",
        "  x = endpoints['Predictions'].eval(feed_dict={file_input: 'soldiers.jpg'})\n",
        "label_map = imagenet.create_readable_names_for_imagenet_labels()  \n",
        "print(\"Top 1 prediction: \", x.argmax(),label_map[x.argmax()], x.max())"
      ],
      "metadata": {
        "id": "dfXzsQ3k1a0e",
        "outputId": "0d12465f-841d-43f9-f254-11349243969a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 prediction:  647 maze, labyrinth 0.1894241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the limitations of the limited computer vision model become apparent as soldiers get classified as a \"Maze\" or \"Labyrinth\"!\n"
      ],
      "metadata": {
        "id": "kGLI8ejbMHUC"
      }
    }
  ]
}